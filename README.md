<a id="readme-top"></a>

<!-- ABOUT THE PROJECT -->
## About The Project

This project focuses on integrating LipNet, a deep learning model designed for lip movement detection, into an Android application. The model processes video inputs to recognize lip movements and translate them into corresponding text. This technology can be used for applications such as speech recognition for the hearing-impaired or silent communication interfaces.

### Built With

This section lists some of the major frameworks/libraries used in the project:

- ![Flask](https://img.shields.io/badge/Flask-000000?logo=flask&logoColor=white)
- ![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?logo=tensorflow&logoColor=white)
- ![Flutter](https://img.shields.io/badge/Flutter-02569B?logo=flutter&logoColor=white)

### Key Feature
- Lip Movement Detection: Uses the LipNet model to analyze lip movements and convert them into text-based predictions.
- Android Compatibility: The model is deployed in a native Android application to ensure real-time processing of video inputs.
- TensorFlow Integration: The deep learning model is powered by TensorFlow, ensuring accuracy and efficiency.
- Flask API: A Flask backend API is used to handle model inference, ensuring smooth interaction between the Android front-end and the TensorFlow model.

